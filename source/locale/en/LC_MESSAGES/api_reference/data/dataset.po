# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018, paddle-dev@baidu.com
# This file is distributed under the same license as the PaddlePaddle Fluid
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddlePaddle Fluid 0.13.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2018-06-15 16:34+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../source/api_reference/data/dataset.rst:2
msgid "Dataset"
msgstr ""

#: of paddle.dataset:1
msgid "Dataset package."
msgstr ""

#: ../../source/api_reference/data/dataset.rst:9
msgid "mnist"
msgstr ""

#: of paddle.dataset.mnist:1
msgid "MNIST dataset."
msgstr ""

#: of paddle.dataset.mnist:3
msgid ""
"This module will download dataset from http://yann.lecun.com/exdb/mnist/ "
"and parse training set and test set into paddle reader creators."
msgstr ""

#: of paddle.dataset.mnist.train:1
msgid "MNIST training set creator."
msgstr ""

#: of paddle.dataset.cifar.test10:3 paddle.dataset.cifar.test100:3
#: paddle.dataset.cifar.train10:3 paddle.dataset.mnist.test:3
#: paddle.dataset.mnist.train:3
msgid ""
"It returns a reader creator, each sample in the reader is image pixels in"
" [0, 1] and label in [0, 9]."
msgstr ""

#: of paddle.dataset.cifar.test10 paddle.dataset.cifar.test100
#: paddle.dataset.cifar.train10 paddle.dataset.cifar.train100
#: paddle.dataset.conll05.test paddle.dataset.imdb.test
#: paddle.dataset.imdb.train paddle.dataset.imikolov.test
#: paddle.dataset.imikolov.train paddle.dataset.mnist.test
#: paddle.dataset.mnist.train paddle.dataset.uci_housing.test
#: paddle.dataset.uci_housing.train paddle.dataset.wmt14.test
#: paddle.dataset.wmt14.train paddle.dataset.wmt16.get_dict
#: paddle.dataset.wmt16.test paddle.dataset.wmt16.train
#: paddle.dataset.wmt16.validation
msgid "返回"
msgstr ""

#: of paddle.dataset.cifar.train10:6 paddle.dataset.cifar.train100:6
#: paddle.dataset.conll05.test:8 paddle.dataset.imdb.train:8
#: paddle.dataset.imikolov.train:12 paddle.dataset.mnist.train:6
#: paddle.dataset.uci_housing.train:6 paddle.dataset.wmt14.train:7
msgid "Training reader creator"
msgstr ""

#: of paddle.dataset.cifar.test10 paddle.dataset.cifar.test100
#: paddle.dataset.cifar.train10 paddle.dataset.cifar.train100
#: paddle.dataset.conll05.test paddle.dataset.imdb.test
#: paddle.dataset.imdb.train paddle.dataset.imikolov.test
#: paddle.dataset.imikolov.train paddle.dataset.mnist.test
#: paddle.dataset.mnist.train paddle.dataset.uci_housing.test
#: paddle.dataset.uci_housing.train paddle.dataset.wmt14.test
#: paddle.dataset.wmt14.train paddle.dataset.wmt16.get_dict
#: paddle.dataset.wmt16.test paddle.dataset.wmt16.train
#: paddle.dataset.wmt16.validation
msgid "返回类型"
msgstr ""

#: of paddle.dataset.mnist.test:1
msgid "MNIST test set creator."
msgstr ""

#: of paddle.dataset.cifar.test10:6 paddle.dataset.cifar.test100:6
#: paddle.dataset.mnist.test:6
msgid "Test reader creator."
msgstr ""

#: of paddle.dataset.cifar.convert:1 paddle.dataset.imdb.convert:1
#: paddle.dataset.imikolov.convert:1 paddle.dataset.mnist.convert:1
#: paddle.dataset.movielens.convert:1 paddle.dataset.sentiment.convert:1
#: paddle.dataset.wmt14.convert:1
msgid "Converts dataset to recordio format"
msgstr ""

#: ../../source/api_reference/data/dataset.rst:16
msgid "cifar"
msgstr ""

#: of paddle.dataset.cifar:1
msgid "CIFAR dataset."
msgstr ""

#: of paddle.dataset.cifar:3
msgid ""
"This module will download dataset from "
"https://www.cs.toronto.edu/~kriz/cifar.html and parse train/test set into"
" paddle reader creators."
msgstr ""

#: of paddle.dataset.cifar:7
msgid ""
"The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes,"
" with 6000 images per class. There are 50000 training images and 10000 "
"test images."
msgstr ""

#: of paddle.dataset.cifar:11
msgid ""
"The CIFAR-100 dataset is just like the CIFAR-10, except it has 100 "
"classes containing 600 images each. There are 500 training images and 100"
" testing images per class."
msgstr ""

#: of paddle.dataset.cifar.train100:1
msgid "CIFAR-100 training set creator."
msgstr ""

#: of paddle.dataset.cifar.train100:3
msgid ""
"It returns a reader creator, each sample in the reader is image pixels in"
" [0, 1] and label in [0, 99]."
msgstr ""

#: of paddle.dataset.cifar.test100:1
msgid "CIFAR-100 test set creator."
msgstr ""

#: of paddle.dataset.cifar.train10:1
msgid "CIFAR-10 training set creator."
msgstr ""

#: of paddle.dataset.cifar.test10:1
msgid "CIFAR-10 test set creator."
msgstr ""

#: ../../source/api_reference/data/dataset.rst:23
msgid "conll05"
msgstr ""

#: of paddle.dataset.conll05:1
msgid ""
"Conll05 dataset. Paddle semantic role labeling Book and demo use this "
"dataset as an example. Because Conll05 is not free in public, the default"
" downloaded URL is test set of Conll05 (which is public). Users can "
"change URL and MD5 to their Conll dataset. And a pre-trained word vector "
"model based on Wikipedia corpus is used to initialize SRL model."
msgstr ""

#: of paddle.dataset.conll05.get_dict:1
msgid "Get the word, verb and label dictionary of Wikipedia corpus."
msgstr ""

#: of paddle.dataset.conll05.get_embedding:1
msgid "Get the trained word vector based on Wikipedia corpus."
msgstr ""

#: of paddle.dataset.conll05.test:1
msgid "Conll05 test set creator."
msgstr ""

#: of paddle.dataset.conll05.test:3
msgid ""
"Because the training dataset is not free, the test dataset is used for "
"training. It returns a reader creator, each sample in the reader is nine "
"features, including sentence sequence, predicate, predicate context, "
"predicate context flag and tagged sequence."
msgstr ""

#: ../../source/api_reference/data/dataset.rst:30
msgid "imdb"
msgstr ""

#: of paddle.dataset.imdb:1
msgid "IMDB dataset."
msgstr ""

#: of paddle.dataset.imdb:3
#, python-format
msgid ""
"This module downloads IMDB dataset from "
"http://ai.stanford.edu/%7Eamaas/data/sentiment/. This dataset contains a "
"set of 25,000 highly polar movie reviews for training, and 25,000 for "
"testing. Besides, this module also provides API for building dictionary."
msgstr ""

#: of paddle.dataset.imdb.build_dict:1
msgid ""
"Build a word dictionary from the corpus. Keys of the dictionary are "
"words, and values are zero-based IDs of these words."
msgstr ""

#: of paddle.dataset.imdb.train:1
msgid "IMDB training set creator."
msgstr ""

#: of paddle.dataset.imdb.test:3 paddle.dataset.imdb.train:3
msgid ""
"It returns a reader creator, each sample in the reader is an zero-based "
"ID sequence and label in [0, 1]."
msgstr ""

#: of paddle.dataset.imdb.test paddle.dataset.imdb.train
#: paddle.dataset.imikolov.test paddle.dataset.imikolov.train
#: paddle.dataset.wmt16.get_dict paddle.dataset.wmt16.test
#: paddle.dataset.wmt16.train paddle.dataset.wmt16.validation
msgid "参数"
msgstr ""

#: of paddle.dataset.imdb.test:6 paddle.dataset.imdb.train:6
#: paddle.dataset.imikolov.test:6 paddle.dataset.imikolov.train:6
msgid "word dictionary"
msgstr ""

#: of paddle.dataset.imdb.test:1
msgid "IMDB test set creator."
msgstr ""

#: of paddle.dataset.imdb.test:8 paddle.dataset.imikolov.test:12
#: paddle.dataset.uci_housing.test:6 paddle.dataset.wmt14.test:7
msgid "Test reader creator"
msgstr ""

#: ../../source/api_reference/data/dataset.rst:37
msgid "imikolov"
msgstr ""

#: of paddle.dataset.imikolov:1
msgid "imikolov's simple dataset."
msgstr ""

#: of paddle.dataset.imikolov:3
msgid ""
"This module will download dataset from "
"http://www.fit.vutbr.cz/~imikolov/rnnlm/ and parse training set and test "
"set into paddle reader creators."
msgstr ""

#: of paddle.dataset.imikolov.train:1
msgid "imikolov training set creator."
msgstr ""

#: of paddle.dataset.imikolov.test:3 paddle.dataset.imikolov.train:3
msgid "It returns a reader creator, each sample in the reader is a word ID tuple."
msgstr ""

#: of paddle.dataset.imikolov.test:8 paddle.dataset.imikolov.train:8
msgid "sliding window size if type is ngram, otherwise max length of sequence"
msgstr ""

#: of paddle.dataset.imikolov.test:10 paddle.dataset.imikolov.train:10
msgid "data type (ngram or sequence)"
msgstr ""

#: of paddle.dataset.imikolov.test:1
msgid "imikolov test set creator."
msgstr ""

#: of paddle.dataset.imikolov.build_dict:1
msgid ""
"Build a word dictionary from the corpus,  Keys of the dictionary are "
"words, and values are zero-based IDs of these words."
msgstr ""

#: ../../source/api_reference/data/dataset.rst:44
msgid "movielens"
msgstr ""

#: of paddle.dataset.movielens:1
msgid "Movielens 1-M dataset."
msgstr ""

#: of paddle.dataset.movielens:3
msgid ""
"Movielens 1-M dataset contains 1 million ratings from 6000 users on 4000 "
"movies, which was collected by GroupLens Research. This module will "
"download Movielens 1-M dataset from "
"http://files.grouplens.org/datasets/movielens/ml-1m.zip and parse "
"training set and test set into paddle reader creators."
msgstr ""

#: of paddle.dataset.movielens.get_movie_title_dict:1
msgid "Get movie title dictionary."
msgstr ""

#: of paddle.dataset.movielens.max_movie_id:1
msgid "Get the maximum value of movie id."
msgstr ""

#: of paddle.dataset.movielens.max_user_id:1
msgid "Get the maximum value of user id."
msgstr ""

#: of paddle.dataset.movielens.movie_categories:1
msgid "Get movie categoriges dictionary."
msgstr ""

#: of paddle.dataset.movielens.max_job_id:1
msgid "Get the maximum value of job id."
msgstr ""

#: of paddle.dataset.movielens.user_info:1
msgid "Get user info dictionary."
msgstr ""

#: of paddle.dataset.movielens.movie_info:1
msgid "Get movie info dictionary."
msgstr ""

#: of paddle.dataset.movielens.MovieInfo:1
msgid "Movie id, title and categories information are stored in MovieInfo."
msgstr ""

#: of paddle.dataset.movielens.UserInfo:1
msgid "User id, gender, age, and job information are stored in UserInfo."
msgstr ""

#: ../../source/api_reference/data/dataset.rst:57
msgid "sentiment"
msgstr ""

#: of paddle.dataset.sentiment:1
msgid ""
"The script fetch and preprocess movie_reviews data set that provided by "
"NLTK"
msgstr ""

#: of paddle.dataset.sentiment:3
msgid "TODO(yuyang18): Complete dataset."
msgstr ""

#: of paddle.dataset.sentiment.train:1
msgid "Default training set reader creator"
msgstr ""

#: of paddle.dataset.sentiment.test:1
msgid "Default test set reader creator"
msgstr ""

#: of paddle.dataset.sentiment.get_word_dict:1
msgid "Sorted the words by the frequency of words which occur in sample :return:"
msgstr ""

#: of paddle.dataset.sentiment.get_word_dict:3
msgid "words_freq_sorted"
msgstr ""

#: ../../source/api_reference/data/dataset.rst:64
msgid "uci_housing"
msgstr ""

#: of paddle.dataset.uci_housing:1
msgid "UCI Housing dataset."
msgstr ""

#: of paddle.dataset.uci_housing:3
msgid ""
"This module will download dataset from https://archive.ics.uci.edu/ml"
"/machine-learning-databases/housing/ and parse training set and test set "
"into paddle reader creators."
msgstr ""

#: of paddle.dataset.uci_housing.train:1
msgid "UCI_HOUSING training set creator."
msgstr ""

#: of paddle.dataset.uci_housing.test:3 paddle.dataset.uci_housing.train:3
msgid ""
"It returns a reader creator, each sample in the reader is features after "
"normalization and price number."
msgstr ""

#: of paddle.dataset.uci_housing.test:1
msgid "UCI_HOUSING test set creator."
msgstr ""

#: ../../source/api_reference/data/dataset.rst:71
msgid "wmt14"
msgstr ""

#: of paddle.dataset.wmt14:1
msgid ""
"WMT14 dataset. The original WMT14 dataset is too large and a small set of"
" data for set is provided. This module will download dataset from "
"http://paddlepaddle.cdn.bcebos.com/demo/wmt_shrinked_data/wmt14.tgz and "
"parse training set and test set into paddle reader creators."
msgstr ""

#: of paddle.dataset.wmt14.train:1
msgid "WMT14 training set creator."
msgstr ""

#: of paddle.dataset.wmt14.test:3 paddle.dataset.wmt14.train:3
msgid ""
"It returns a reader creator, each sample in the reader is source language"
" word ID sequence, target language word ID sequence and next word ID "
"sequence."
msgstr ""

#: of paddle.dataset.wmt14.test:1
msgid "WMT14 test set creator."
msgstr ""

#: ../../source/api_reference/data/dataset.rst:78
msgid "wmt16"
msgstr ""

#: of paddle.dataset.wmt16:1
msgid ""
"ACL2016 Multimodal Machine Translation. Please see this website for more "
"details: http://www.statmt.org/wmt16/multimodal-task.html#task1"
msgstr ""

#: of paddle.dataset.wmt16:4
msgid ""
"If you use the dataset created for your task, please cite the following "
"paper: Multi30K: Multilingual English-German Image Descriptions."
msgstr ""

#: of paddle.dataset.wmt16:12
msgid "@article{elliott-EtAl:2016:VL16,"
msgstr ""

#: of paddle.dataset.wmt16:8
msgid ""
"author    = {{Elliott}, D. and {Frank}, S. and {Sima\"an}, K. and "
"{Specia}, L.}, title     = {Multi30K: Multilingual English-German Image "
"Descriptions}, booktitle = {Proceedings of the 6th Workshop on Vision and"
" Language}, year      = {2016}, pages     = {70--74}, year      = 2016"
msgstr ""

#: of paddle.dataset.wmt16:14
msgid "}"
msgstr ""

#: of paddle.dataset.wmt16.train:1
msgid "WMT16 train set reader."
msgstr ""

#: of paddle.dataset.wmt16.train:3
msgid ""
"This function returns the reader for train data. Each sample the reader "
"returns is made up of three fields: the source language word index "
"sequence, target language word index sequence and next word index "
"sequence."
msgstr ""

#: of paddle.dataset.wmt16.train:8
msgid ""
"NOTE: The original like for training data is: "
"http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/training.tar.gz"
msgstr ""

#: of paddle.dataset.wmt16.test:11 paddle.dataset.wmt16.train:12
#: paddle.dataset.wmt16.validation:11
msgid ""
"paddle.dataset.wmt16 provides a tokenized version of the original dataset"
" by using moses's tokenization script: https://github.com/moses-"
"smt/mosesdecoder/blob/master/scripts/tokenizer/tokenizer.perl"
msgstr ""

#: of paddle.dataset.wmt16.test:15 paddle.dataset.wmt16.train:16
#: paddle.dataset.wmt16.validation:15
msgid ""
"Size of the source language dictionary. Three special tokens will be "
"added into the dictionary: <s> for start mark, <e> for end mark, and "
"<unk> for unknown word."
msgstr ""

#: of paddle.dataset.wmt16.test:20 paddle.dataset.wmt16.train:21
#: paddle.dataset.wmt16.validation:20
msgid ""
"Size of the target language dictionary. Three special tokens will be "
"added into the dictionary: <s> for start mark, <e> for end mark, and "
"<unk> for unknown word."
msgstr ""

#: of paddle.dataset.wmt16.get_dict:3 paddle.dataset.wmt16.test:25
#: paddle.dataset.wmt16.train:26 paddle.dataset.wmt16.validation:25
msgid ""
"A string indicating which language is the source language. Available "
"options are: \"en\" for English and \"de\" for Germany."
msgstr ""

#: of paddle.dataset.wmt16.train:31
msgid "The train reader."
msgstr ""

#: of paddle.dataset.wmt16.test:1
msgid "WMT16 test set reader."
msgstr ""

#: of paddle.dataset.wmt16.test:3
msgid ""
"This function returns the reader for test data. Each sample the reader "
"returns is made up of three fields: the source language word index "
"sequence, target language word index sequence and next word index "
"sequence."
msgstr ""

#: of paddle.dataset.wmt16.test:7
msgid ""
"NOTE: The original like for test data is: "
"http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/mmt16_task1_test.tar.gz"
msgstr ""

#: of paddle.dataset.wmt16.test:30
msgid "The test reader."
msgstr ""

#: of paddle.dataset.wmt16.validation:1
msgid "WMT16 validation set reader."
msgstr ""

#: of paddle.dataset.wmt16.validation:3
msgid ""
"This function returns the reader for validation data. Each sample the "
"reader returns is made up of three fields: the source language word index"
" sequence, target language word index sequence and next word index "
"sequence."
msgstr ""

#: of paddle.dataset.wmt16.validation:7
msgid ""
"NOTE: The original like for validation data is: "
"http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/validation.tar.gz"
msgstr ""

#: of paddle.dataset.wmt16.validation:30
msgid "The validation reader."
msgstr ""

#: of paddle.dataset.wmt16.convert:1
msgid "Converts dataset to recordio format."
msgstr ""

#: of paddle.dataset.wmt16.fetch:1
msgid "download the entire dataset."
msgstr ""

#: of paddle.dataset.wmt16.get_dict:1
msgid "return the word dictionary for the specified language."
msgstr ""

#: of paddle.dataset.wmt16.get_dict:7
msgid "Size of the specified language dictionary."
msgstr ""

#: of paddle.dataset.wmt16.get_dict:9
msgid ""
"If reverse is set to False, the returned python dictionary will use word "
"as key and use index as value. If reverse is set to True, the returned "
"python dictionary will use index as key and word as value."
msgstr ""

#: of paddle.dataset.wmt16.get_dict:15
msgid "The word dictionary for the specific language."
msgstr ""

